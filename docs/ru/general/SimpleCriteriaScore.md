# Метрика SimpleCriteriaScore

## Содержание

- [Обзор](#обзор)
- [Когда использовать](#когда-использовать)
- [Ключевые особенности](#ключевые-особенности)
- [Критические выводы из тестирования](#критические-выводы-из-тестирования)
- [Анализ производительности моделей](#анализ-производительности-моделей)
- [Примеры использования](#примеры-использования)
- [Параметры конфигурации](#параметры-конфигурации)
- [Как работает метрика](#как-работает-метрика)
- [Лучшие практики](#лучшие-практики)
- [Формулирование эффективных критериев](#формулирование-эффективных-критериев)

---

## Обзор

`SimpleCriteriaScore` — это метрика оценки "по шкале", которая проверяет ответы ИИ на соответствие
определяемым критериям. В отличие от бинарных метрик, метрика предоставляет **детальные числовые оценки**
(например, по шкале 0-5) с подробным обоснованием, что делает её идеальной для оценки качества.

**Ключевые характеристики:**

- Возвращает оценки в настраиваемом диапазоне (по умолчанию: 0.0-5.0)
- Предоставляет подробное обоснование каждой оценки
- Сравнивает ответы с эталонными, если они есть

## Когда использовать

### Идеальные сценарии

- **Оценка качества**: Проверка полноты, точности или полезности ответа по шкале
- **Сравнительная оценка**: Измерение схожести с эталонными ответами с детальной оценкой
- **Многоуровневая оценка**: Когда бинарного true/false недостаточно и нужны степени правильности
- **Полнота содержания**: Оценка того, насколько исчерпывающе раскрыта тема

### Что метрика МОЖЕТ делать

- ✅ Предоставлять **тонкую оценку** для частично правильных ответов
- ✅ Различать **степени качества** (плохо, средне, хорошо, отлично)
- ✅ Проверять **уровни полноты** (отсутствие некоторой vs. всей информации)
- ✅ Сравнивать ответы с эталонами через **оценку схожести**
- ✅ Генерировать **подробное обоснование**, объясняющее присвоение оценки

### Что метрика НЕ МОЖЕТ делать

- ❌ Предоставлять **объективные оценки** для субъективных критериев
- ❌ Надёжно работать без **чётких эталонных ответов** для задач сравнения
- ❌ Исключать **вариативность оценок** между запусками оценки
- ❌ Оценивать несколько критериев за один раз

## Ключевые особенности

**Диапазон непрерывной оценки:**

- По умолчанию: шкала 0.0-5.0
- Настраиваемые минимальные/максимальные значения
- Поддержка любого разумного числового диапазона по шкале от и до

**Структурированный вывод:**

- **criteria**: Применяемый критерий оценки
- **score**: Числовая оценка в заданном диапазоне
- **reasoning**: Подробное объяснение присвоения оценки

**Гибкая оценка:**

- Сравнение с эталонными ответами при их наличии
- Работа с эталоном или без него
- Одинаково хорошо обрабатывает русский и английский текст

## Критические выводы из тестирования

### Анализ консистентности оценок

На основе обширного тестирования с 17 тестовыми запусками по критерию "Математическая точность":

**Для правильных ответов:**

- **Идеальные оценки (5.0)**: 16/17 запусков (94%)
- **Хорошие оченки (4.5-4.9)**: 0/17 запусков (0%)
- **Средние оценки (<4.5)**: 1/17 запусков (6%)

**Для неправильных ответов:**

- **Корректные оценки**: 15/17 запусков (88%)
- **Частичная корректность**: 2/17 запусков (12%)
  - Два случая (модели очень мягко интерпретировали некорректный результат)

### Ключевые наблюдения

**Высокая надёжность для чётких случаев:**

```
✅ Правильные математические ответы: 94% получают 5.0
✅ Неправильные ответы: 88% получают 0.0
```

**Редкие пограничные случаи:**

```
⚠️ ~6-12% вероятность неожиданных оценок
⚠️ Большинство аномалий возникает с правильными ответами (более строгая оценка)
⚠️ Очень редкие ложные положительные результаты для неправильных ответов
```

**Паттерн распределения оценок:**

- **Бимодальное распределение**: Оценки группируются на крайних значениях (0.0 и 5.0)
- **Редкие промежуточные оценки**: Для чётких критериев промежуточные оценки редки
- **Консистентное обоснование**: Даже аномальные оценки имеют логические объяснения

## Анализ производительности моделей

### Методология тестирования

**Настройка теста:**

- **Критерий**: "Математическая точность" (Математическая точность)
- **Тестовые случаи**:
  - Правильный: "15 умножить на 12 равно 180."
  - Неправильный: "15 умножить на 12 равно 170."
- **Запуски**: 17 циклов оценки на разных моделях
- **Диапазон оценок**: 0.0-5.0

### Наблюдаемые паттерны

**Результаты позитивного теста (Правильный ответ: "15 × 12 = 180"):**

| Запуск |              Модель               | Оценка правильного ответа | Оценка неправильного ответа |
|--------|-----------------------------------|---------------------------|-----------------------------|
| 1      | x-ai/grok-code-fast-1             | 5.0 ✅                     | 0.0 ✅                       |
| 2      | x-ai/grok-4.1-fast                | 5.0 ✅                     | 0.0 ✅                       |
| 3      | google/gemini-2.5-flash           | 5.0 ✅                     | 0.0 ✅                       |
| 4      | google/gemini-2.5-pro             | 5.0 ✅                     | 0.0 ✅                       |
| 5      | minimax/minimax-m2                | 5.0 ✅                     | 0.0 ✅                       |
| 6      | anthropic/claude-sonnet-4.5       | 5.0 ✅                     | 0.0 ✅                       |
| 7      | anthropic/claude-haiku-4.5        | 5.0 ✅                     | 0.0 ✅                       |
| 8      | deepseek/deepseek-chat-v3-0324    | 5.0 ✅                     | 0.0 ✅                       |
| 9      | deepseek/deepseek-chat-v3.1       | 5.0 ✅                     | 0.0 ✅                       |
| 10     | qwen/qwen3-235b-a22b-2507         | 5.0 ✅                     | 1.0 ⚠️                      |
| 11     | qwen/qwen3-coder-30b-a3b-instruct | 5.0 ✅                     | 1.0 ⚠️                      |
| 12     | z-ai/glm-4.6                      | 5.0 ✅                     | 0.0 ✅                       |
| 13     | openai/gpt-5-mini                 | 5.0 ✅                     | 0.0 ✅                       |
| 14     | openai/gpt-5.1                    | 5.0 ✅                     | 0.0 ✅                       |
| 15     | openai/gpt-4o-mini                | 0.0 ❌                     | 0.0 ✅                       |
| 16     | openai/gpt-oss-120b               | 5.0 ✅                     | 0.0 ✅                       |
| 17     | openai/gpt-oss-20b                | 5.0 ✅                     | 0.0 ✅                       |

**Негативный тест (Плохое качество ответа):**

Все 17 запусков консистентно выставили низкие оценки (1.0-1.5) для объективно плохих ответов о квантовой физике,
демонстрируя отличную дискриминацию между уровнями качества.

### Результаты по конкретным моделям

**Наиболее надёжные модели (Идеальная производительность):**

- **x-ai/grok-code-fast-1**: 5.0/0.0 ✅✅
- **x-ai/grok-4.1-fast**: 5.0/0.0 ✅✅
- **google/gemini-2.5-flash**: 5.0/0.0 ✅✅
- **google/gemini-2.5-pro**: 5.0/0.0 ✅✅
- **minimax/minimax-m2**: 5.0/0.0 ✅✅
- **anthropic/claude-sonnet-4.5**: 5.0/0.0 ✅✅
- **anthropic/claude-haiku-4.5**: 5.0/0.0 ✅✅
- **deepseek/deepseek-chat-v3-0324**: 5.0/0.0 ✅✅
- **deepseek/deepseek-chat-v3.1**: 5.0/0.0 ✅✅
- **z-ai/glm-4.6**: 5.0/0.0 ✅✅
- **openai/gpt-5-mini**: 5.0/0.0 ✅✅
- **openai/gpt-5.1**: 5.0/0.0 ✅✅
- **openai/gpt-oss-120b**: 5.0/0.0 ✅✅
- **openai/gpt-oss-20b**: 5.0/0.0 ✅✅

**Модели с незначительными проблемами:**

- **qwen/qwen3-235b-a22b-2507**: 5.0/1.0 ⚠️ (мягкая оценка неправильного ответа)
- **qwen/qwen3-coder-30b-a3b-instruct**: 5.0/1.0 ⚠️ (мягкая оценка неправильного ответа)
- **openai/gpt-4o-mini**: 0.0/0.0 ❌ (ложный отрицательный результат для правильного ответа)

### Метрики надёжности

**Общая точность:**

- **Правильные ответы оценены правильно**: 94% (16/17)
- **Неправильные ответы оценены правильно**: 88% (15/17)
- **Комбинированная надёжность**: 91% (31/34 оценки)

**Типы ошибок:**

1. **Ложный отрицательный (6%)**: Правильный ответ оценён как 0.0 (Запуск 15)
2. **Ложные положительные (12%)**: Неправильный ответ оценён как 1.0 (Запуски 10-11)
3. **Общий уровень ошибок**: ~9%

## Примеры использования

### Пример 1: Оценка математической точности

```java
import ai.qa.solutions.metrics.general.SimpleCriteriaScoreMetric;
import ai.qa.solutions.sample.Sample;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.junit.jupiter.api.Test;

@SpringBootTest
class SimpleCriteriaScoreTest {

    @Autowired
    private SimpleCriteriaScoreMetric simpleCriteriaScoreMetric;

    @Test
    void testMathematicalAccuracy() {
        // ✅ ПРИМЕР 1: Правильный математический ответ
        Sample correctSample = Sample.builder()
                .userInput("Сколько будет 15 умножить на 12?")
                .response("15 умножить на 12 равно 180.")
                .reference("180")
                .build();

        SimpleCriteriaScoreMetric.SimpleCriteriaConfig config =
                SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
                        .definition("Математическая точность")
                        .minScore(0.0)
                        .maxScore(5.0)
                        .build();

        Double score = simpleCriteriaScoreMetric.singleTurnScore(config, correctSample);
        // Ожидается: 5.0 (вероятность 94%)
        // Фактические результаты: 16/17 запусков = 5.0 ✅

        System.out.println("Оценка правильного ответа: " + score);
    }

    @Test
    void testIncorrectAnswer() {
        // ✅ ПРИМЕР 2: Неправильный математический ответ
        Sample incorrectSample = Sample.builder()
                .userInput("Сколько будет 15 умножить на 12?")
                .response("15 умножить на 12 равно 170.")
                .reference("180")
                .build();

        SimpleCriteriaScoreMetric.SimpleCriteriaConfig config =
                SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
                        .definition("Математическая точность")
                        .minScore(0.0)
                        .maxScore(5.0)
                        .build();

        Double score = simpleCriteriaScoreMetric.singleTurnScore(config, incorrectSample);
        // Ожидается: 0.0 (вероятность 88%)
        // Фактические результаты: 15/17 запусков = 0.0 ✅

        System.out.println("Оценка неправильного ответа: " + score);
    }
}
```

### Пример 2: Оценка качества ответа

```java

@Test
void testResponseQuality() {
    // ✅ ПРИМЕР 3: Оценка качества с подробным ответом
    Sample sample = Sample.builder()
            .userInput("Объясните, что такое искусственный интеллект")
            .response("Искусственный интеллект (ИИ) — это область информатики, которая " +
                    "занимается созданием систем, способных выполнять задачи, обычно " +
                    "требующие человеческого интеллекта. Это включает обучение, рассуждение, " +
                    "восприятие и принятие решений. ИИ используется в различных областях: " +
                    "от медицины до автономных автомобилей.")
            .reference("Искусственный интеллект — это технология, имитирующая " +
                    "человеческое мышление для решения сложных задач.")
            .build();

    SimpleCriteriaScoreMetric.SimpleCriteriaConfig config =
            SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
                    .definition("Полнота и точность ответа по сравнению с эталоном")
                    .minScore(1.0)
                    .maxScore(5.0)
                    .build();

    Double score = simpleCriteriaScoreMetric.singleTurnScore(config, sample);
    // Ожидается: 4.0-5.0 (исчерпывающий ответ)

    System.out.println("Оценка качества: " + score);
}
```

### Пример 3: Обнаружение плохих ответов

```java

@Test
void testPoorResponse() {
    // ✅ ПРИМЕР 4: Обнаружение низкокачественных ответов
    Sample sample = Sample.builder()
            .userInput("Объясните принципы квантовой физики")
            .response("Квантовая физика это сложно. Там всякие частицы " +
                    "и волны. Не знаю, что еще сказать.")
            .reference("Квантовая физика изучает поведение материи и " +
                    "энергии на атомном и субатомном уровне, где действуют " +
                    "принципы неопределенности и суперпозиции.")
            .build();

    SimpleCriteriaScoreMetric.SimpleCriteriaConfig config =
            SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
                    .definition("Качество и полнота ответа")
                    .minScore(1.0)
                    .maxScore(5.0)
                    .build();

    Double score = simpleCriteriaScoreMetric.singleTurnScore(config, sample);
    // Ожидается: 1.0-1.5 (плохое качество, расплывчатый ответ)
    // Результаты теста: Консистентно 1.0-1.5 во всех 17 запусках ✅

    System.out.println("Оценка плохого ответа: " + score);
}
```

### Пример 4: Пользовательский диапазон оценок

```java

@Test
void testCustomScoreRange() {
    // ✅ ПРИМЕР 5: Использование пользовательской шкалы 0-10
    Sample sample = Sample.builder()
            .userInput("Какие бывают основные цвета?")
            .response("Основные цвета — это красный, синий и жёлтый.")
            .reference("Красный, синий и жёлтый — это основные цвета.")
            .build();

    SimpleCriteriaScoreMetric.SimpleCriteriaConfig config =
            SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
                    .definition("Точность и полнота информации о цветах")
                    .minScore(0.0)
                    .maxScore(10.0)
                    .build();

    Double score = simpleCriteriaScoreMetric.singleTurnScore(config, sample);
    // Ожидается: 8.0-10.0 (правильно и полно)

    System.out.println("Оценка по шкале 0-10: " + score);
}
```

### Пример 5: Асинхронная оценка

```java

@Test
void testAsyncScoring() throws Exception {
    // ✅ ПРИМЕР 6: Асинхронная оценка для пакетной обработки
    Sample sample = Sample.builder()
            .userInput("Что такое машинное обучение?")
            .response("Машинное обучение — это подмножество ИИ, которое позволяет " +
                    "системам учиться на данных без явного программирования.")
            .reference("Машинное обучение позволяет компьютерам учиться на опыте.")
            .build();

    SimpleCriteriaScoreMetric.SimpleCriteriaConfig config =
            SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
                    .definition("Техническая точность и ясность")
                    .build();

    CompletableFuture<Double> futureScore =
            simpleCriteriaScoreMetric.singleTurnScoreAsync(config, sample);

    Double score = futureScore.get();
    System.out.println("Асинхронная оценка: " + score);
}
```

## Параметры конфигурации

|   Параметр   |  Тип   | Обязательный | По умолчанию |                                                     Описание                                                      |
|--------------|--------|--------------|--------------|-------------------------------------------------------------------------------------------------------------------|
| `definition` | String | Да           | -            | **Критерий оценки** - определяет, какой аспект оценивать (например, "Математическая точность", "Качество ответа") |
| `minScore`   | Double | Нет          | 0.0          | Минимальное значение диапазона оценки                                                                             |
| `maxScore`   | Double | Нет          | 5.0          | Максимальное значение диапазона оценки                                                                            |

### Рекомендации по параметрам

**Definition (Определение):**

```java
// ✅ ХОРОШИЕ определения
"Математическая точность"
        "Полнота и точность ответа по сравнению с эталоном"
        "Техническая точность и ясность"

// ❌ ПЛОХИЕ определения
        "Качество" // слишком расплывчато
        "Хороший ли ответ?" // вопросительная форма
        "Оцените это" // нет чётких критериев
```

**Диапазон оценок:**

```java
// ✅ Распространённые диапазоны
.minScore(0.0).

maxScore(5.0)  // Стандартная 5-балльная шкала
.

minScore(1.0).

maxScore(5.0)  // Без нуля, начинается с 1
.

minScore(0.0).

maxScore(10.0) // Расширенная 10-балльная шкала
.

minScore(0.0).

maxScore(1.0)  // Нормализованный диапазон 0-1

// ⚠️ Валидация
.

minScore(5.0).

maxScore(0.0)  // ❌ Выбрасывает IllegalArgumentException
```

## Как работает метрика

### Процесс оценки

1. **Конструирование промпта**: Создаёт оценочный промпт с:
   - Пользовательским вводом (вопрос/контекст)
   - Ответом ИИ (для оценки)
   - Эталонным ответом (если предоставлен)
   - Определением критерия оценки
   - Диапазоном оценок (мин/макс)
2. **Оценка LLM**: Отправляет структурированный промпт LLM, запрашивая:

```json
   {
  "criteria": "Критерий оценки",
  "score": 4.5,
  "reasoning": "Подробное объяснение..."
}
```

3. **Парсинг структурированного вывода**: Использует маппинг сущностей Spring AI для парсинга JSON-ответа

4. **Извлечение оценки**: Возвращает числовую оценку из ответа

5. **Нормализация**: Возвращает 0.0 при сбое парсинга или если оценка null

### Шаблон промпта

```
Оцените ответ ИИ на основе заданного критерия и выставьте оценку соответственно.

Критерий оценки: {definition}

Ввод пользователя: {user_input}
Ответ ИИ: {response}
Эталонный ответ: {reference}

Инструкции:
1. Сравните ответ ИИ с эталонным ответом
2. Оцените на основе указанного критерия: {definition}
3. Предоставьте оценку между {min_score} и {max_score}
4. Более высокие оценки указывают на лучшее соответствие критерию
5. Предоставьте подробное обоснование вашей оценки

Ответьте JSON-объектом, содержащим:
- criteria: Применяемый критерий оценки
- score: Числовая оценка между {min_score} и {max_score}
- reasoning: Ваше подробное объяснение оценки
```

## Лучшие практики

### ДЕЛАЙТЕ ✅

1. **Используйте чёткие, конкретные критерии:**

```java
   // ✅ Конкретно
   .definition("Математическая точность арифметических операций")

// ❌ Расплывчато
   .

definition("Качество")
```

2. **Предоставляйте эталонные ответы по возможности:**

```java
   Sample.builder()
           .

userInput("Сколько будет 2 + 2?")
           .

response("2 + 2 = 4")
           .

reference("4")  // ✅ Помогает калибровать оценку
           .

build();
```

3. **Выбирайте подходящие диапазоны оценок:**

```java
   // ✅ Бинарно-подобный с нюансами
   .minScore(0.0).

maxScore(5.0)

// ✅ Расширенный диапазон для тонкой градации
   .

minScore(0.0).

maxScore(10.0)
```

4. **Проводите множественные оценки для критических решений:**

```java
   // ✅ Усреднение нескольких запусков для снижения вариативности
List<Double> scores = new ArrayList<>();
   for(
int i = 0;
i< 3;i++){
        scores.

add(metric.singleTurnScore(config, sample));
        }
double avgScore = scores.stream().mapToDouble(Double::doubleValue).average().orElse(0.0);
```

5. **Выбирайте надёжные модели на основе тестирования:**

```java
   // ✅ Рекомендуемые модели (идеальная производительность в тестах):
// - anthropic/claude-sonnet-4.5
// - google/gemini-2.5-flash
// - openai/gpt-5.1
// - deepseek/deepseek-chat-v3-0324

// ⚠️ Модели с известными проблемами:
// - openai/gpt-4o-mini (ложные отрицательные результаты)
// - qwen/qwen3-235b-a22b-2507 (мягкая оценка ошибок)
// - qwen/qwen3-coder-30b-a3b-instruct (мягкая оценка ошибок)
```

### НЕ ДЕЛАЙТЕ ❌

1. **Не используйте вопросительные критерии:**

```java
   // ❌ Неоднозначно
   .definition("Правильный ли ответ?")

// ✅ Чётко
   .

definition("Правильность ответа по сравнению с эталоном")
```

2. **Не ожидайте идеальной консистентности:**

```java
   // ❌ Предположение точной воспроизводимости
   assert score ==5.0; // Может не сработать ~6% времени даже для правильных ответов

        // ✅ Учёт вариативности
        assert score >=4.0; // Более устойчивый порог
```

3. **Не используйте для субъективных критериев без чётких рубрик:**

```java
   // ❌ Субъективно
   .definition("Интересность ответа")

// ✅ Объективно
   .

definition("Количество конкретных примеров (шкала 0-5)")
```

4. **Не игнорируйте эталонный контекст:**

```java
// ❌ Отсутствует эталон для задач сравнения
Sample.builder()
 .userInput("Переведите на французский: Привет")
 .response("Bonjour")
 // Отсутствует .reference("Bonjour")
 .build();
```

## Формулирование эффективных критериев

### Принципы хороших критериев

**1. Будьте конкретны и измеримы:**

```java
// ❌ Расплывчато
"Качество ответа"

// ✅ Конкретно
        "Математическая точность вычислений"
        "Наличие всех трёх основных тезисов ответе (и тут перечисление тезисов)"
        "Схожесть с эталонным ответом по смыслу"
```

**2. Используйте утвердительные формулировки:**

```java
// ❌ Негативное
"Ответ не содержит ошибок"

// ✅ Утвердительное
        "Ответ содержит точную информацию"
```

**3. Фокусируйтесь на одном аспекте:**

```java
// ❌ Многомерное
"Оцени точность, полноту, стиль и тон"

// ✅ Одно измерение
        "Оцени фактическую точность"
```

**4. Согласуйте с диапазоном оценок:**

```java
// ✅ Для шкалы 0-5
"Уровень детализации объяснения (0=минимальный, 5=исчерпывающий)"

// ✅ Для шкалы 0-10
        "Ясность объяснения (0=запутанно, 10=структурированно и логично)"
```

### Примеры критериев по сценарию использования

**Математическая оценка:**

```java
"Математическая точность и правильность вычислений"
        "Точность числовых ответов"
        "Правильное применение математических формул"
```

**Качество содержания:**

```java
"Полнота информации по сравнению с эталоном"
        "Глубина объяснения и уровень детализации"
        "Исчерпывающее раскрытие темы"
```

**Техническая точность:**

```java
"Техническая правильность программных концепций"
        "Точность использования научной терминологии"
        "Правильность фактических утверждений"
```

**Оценка схожести:**

```java
"Семантическая схожесть с эталонным ответом"
        "Соответствие ожидаемой структуре ответа"
        "Консистентность со смыслом эталона"
```

### Тестирование ваших критериев

**Контрольный список валидации:**

1. ✅ Проведите 3-5 тестовых оценок с чёткими правильными/неправильными примерами
2. ✅ Проверьте, что распределение оценок соответствует ожиданиям
3. ✅ Проверьте выводы обоснований на логическую консистентность
4. ✅ Протестируйте пограничные случаи (частично правильные, неоднозначные ответы)
5. ✅ Убедитесь, что оценки совпадают с человеческой оценкой

**Пример валидации:**

```java

@Test
void validateCriteria() {
    var config = SimpleCriteriaConfig.builder()
            .definition("Ваш критерий здесь")
            .build();

    // Тест с очевидно правильным ответом
    var correctSample = Sample.builder()
            .userInput("Вопрос")
            .response("Идеальный ответ")
            .reference("Идеальный ответ")
            .build();

    Double correctScore = metric.singleTurnScore(config, correctSample);
    System.out.println("Оценка правильного: " + correctScore);

    // Тест с очевидно неправильным ответом
    var incorrectSample = Sample.builder()
            .userInput("Вопрос")
            .response("Неправильный ответ")
            .reference("Идеальный ответ")
            .build();

    Double incorrectScore = metric.singleTurnScore(config, incorrectSample);
    System.out.println("Оценка неправильного: " + incorrectScore);

    // Валидация разделения
    assert correctScore > incorrectScore + 2.0; // Должно быть чёткое разделение
}
```

---

## Резюме

**SimpleCriteriaScore — надёжная метрика для непрерывной оценки, когда:**

1. ✅ Критерии **чёткие и конкретные**
2. ✅ Эталонные ответы **предоставлены для сравнения**
3. ✅ Случаи оценки имеют **объективные измерения**
4. ✅ Вы используете **протестированные и надёжные модели**

**Ключевые преимущества:**

- 91% надёжность для точных вопросов
- Детальная оценка передаёт конкретный аспект
- Подробное обоснование помогает в отладке
- Гибкие диапазоны оценок

**Ключевые ограничения:**

- ~9% уровень ошибок даже с хорошими критериями
- Консистентность оценок зависит от моделей
- Требует хорошо сформулированных критериев
- Не подходит для субъективной оценки

**Рекомендуемые модели:**

- anthropic/claude-sonnet-4.5
- google/gemini-2.5-flash
- google/gemini-2.5-pro
- deepseek/deepseek-chat-v3-0324
- openai/gpt-5.1
- openai/gpt-oss-120b

**Модели, которых следует избегать:**

- openai/gpt-4o-mini (ложные отрицательные результаты)
- qwen/qwen3-235b-a22b-2507 (чрезмерно мягкая оценка)
- qwen/qwen3-coder-30b-a3b-instruct (чрезмерно мягкая оценка)

