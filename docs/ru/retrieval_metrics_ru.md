# Метрики извлечения (Retrieval Metrics)

Метрики извлечения — это специализированные инструменты оценки, предназначенные для анализа производительности
систем генерации с дополнением поиска (RAG). Эти метрики оценивают, насколько хорошо найденные контексты
поддерживают генерацию ответов и измеряют различные аспекты качества извлечения.

## Содержание

- [Когда использовать](#когда-использовать)
- [ContextEntityRecall](#contextentityrecall)
- [ContextPrecision](#contextprecision)
- [ContextRecall](#contextrecall)
- [Faithfulness](#faithfulness)
- [NoiseSensitivity](#noisesensitivity)
- [ResponseRelevancy](#responserelevancy)
- [Выбор подходящей метрики](#выбор-подходящей-метрики)
- [Best Practices](#best-practices)
- [Troubleshooting](#troubleshooting)
- [Расширенные примеры](#расширенные-примеры)

## Когда использовать

**Используйте метрики извлечения когда:**
- Оцениваете производительность RAG-систем
- Анализируете качество механизмов извлечения
- Измеряете фактическую согласованность между ответами и контекстами
- Оптимизируете параметры и стратегии извлечения
- Сравниваете различные подходы к извлечению
- Обнаруживаете галлюцинации и фактические ошибки
- Оцениваете покрытие сущностей в фактологических приложениях

**Не используйте эти метрики когда:**
- Оцениваете общее качество ответов без контекста извлечения
- Анализируете творческий или субъективный контент, где фактическая точность не первична
- Работаете с системами, которые не используют найденные контексты
- Измеряете технические аспекты производительности (латентность, стоимость)

---

## ContextEntityRecall

`ContextEntityRecall` измеряет отзыв сущностей, присутствующих как в эталонном, так и в найденных контекстах, относительно сущностей только в эталоне. Эта метрика особенно полезна для фактологических приложений, таких как туристические справочные системы или исторические QA-системы.

### Когда применять

**Идеальные сценарии:**
- **Туристические и туристические системы**: Обеспечение покрытия всех упомянутых мест, дат и достопримечательностей
- **Исторические QA-системы**: Проверка покрытия людей, дат, событий и местоположений
- **Образовательный контент**: Проверка доступности всех ключевых терминов и понятий
- **Новости и информационное извлечение**: Обеспечение всестороннего покрытия сущностей
- **Оценка базы знаний**: Оценка полноты фактической информации

**Преимущества:**
- Фокусируется на конкретных, проверяемых сущностях
- Языково-агностический подход к оценке
- Полезен для измерения всесторонности извлечения
- Обрабатывает различные типы сущностей (люди, места, даты, числа)

**Ограничения:**
- Измеряет только покрытие сущностей, а не семантическую полноту
- Может пропустить важную концептуальную информацию
- Требует четких возможностей извлечения сущностей

### Пример использования

```java
import ai.qa.solutions.metrics.retrieval.ContextEntityRecallMetric;
import ai.qa.solutions.sample.Sample;

Sample sample = Sample.builder()
        .reference("Эйфелева башня расположена в Париже, Франция. Она была завершена в 1889 году для Всемирной выставки.")
        .retrievedContexts(List.of(
                "Эйфелева башня, расположенная в Париже, Франция, является одной из самых знаковых достопримечательностей мира.",
                "Завершенная в 1889 году, она была построена как раз к Всемирной выставке 1889 года.",
                "Миллионы посетителей ежегодно привлекаются к ней захватывающими видами на город."))
        .build();

ContextEntityRecallMetric.ContextEntityRecallConfig config = 
        ContextEntityRecallMetric.ContextEntityRecallConfig.builder().build();

ContextEntityRecallMetric metric = new ContextEntityRecallMetric(chatClient);
Double score = metric.singleTurnScore(config, sample);
// Результат: ~0.9 (высокое покрытие сущностей)
```

### Как работает метрика

1. **Извлечение сущностей**: Извлекает именованные сущности из эталонного ответа с помощью LLM
2. **Анализ контекста**: Извлекает сущности из найденных контекстов
3. **Вычисление отзыва**: Вычисляет пересечение между эталонными и контекстными сущностями
4. **Вычисление оценки**: Возвращает отношение покрытых сущностей к общему количеству эталонных сущностей

**Обнаруживаемые типы сущностей:**
- Имена людей (Альберт Эйнштейн, Наполеон)
- Названия мест (Париж, Эйфелева башня, Франция)
- Организации (ЮНЕСКО, Европейский союз)
- Даты и время (1889, 16 июля 1969)
- События (Вторая мировая война, миссия Аполлон-11)
- Продукты/объекты (iPhone, Великая китайская стена)
- Числа и измерения (21,196 километров, 50,000 зрителей)

### Интерпретация результатов

- **0.9-1.0**: Отличное покрытие сущностей, большинство сущностей найдено
- **0.7-0.9**: Хорошее покрытие, возможно отсутствие незначительных сущностей
- **0.5-0.7**: Умеренное покрытие, отсутствует несколько важных сущностей
- **0.3-0.5**: Плохое покрытие, значительные пробелы в информации о сущностях
- **0.0-0.3**: Очень плохое покрытие, большинство сущностей не найдено

---

## ContextPrecision

`ContextPrecision` оценивает способность извлекателя ранжировать релевантные фрагменты выше в списке найденных контекстов. Автоматически выбирает между оценкой на основе эталона или ответа в зависимости от доступных данных.

### Когда применять

**Идеальные сценарии:**
- **Оптимизация системы извлечения**: Измерение качества ранжирования найденных документов
- **Оценка релевантности поиска**: Оценка того, насколько хорошо приоритизируются релевантные документы
- **Настройка RAG-системы**: Оптимизация параметров извлечения для лучшей точности
- **Сравнительный анализ извлечения**: Сравнение различных стратегий извлечения
- **Контроль качества**: Мониторинг производительности извлечения в продакшене

**Преимущества:**
- Адаптируется к доступным данным (на основе эталона или ответа)
- Учитывает порядок ранжирования, а не только наличие релевантного контента
- Обеспечивает нюансированную оценку качества извлечения
- Подходит как для контролируемых, так и для неконтролируемых сценариев

**Ограничения:**
- Требует множественных найденных контекстов для значимой оценки
- Может быть чувствительным к согласованности оценки LLM
- Не измеряет аспекты отзыва извлечения

### Пример использования

```java
import ai.qa.solutions.metrics.retrieval.ContextPrecisionMetric;

Sample sample = Sample.builder()
        .userInput("Что такое машинное обучение?")
        .reference("Машинное обучение - это ветвь ИИ, которая использует данные и алгоритмы для обучения.")
        .retrievedContexts(List.of(
                "Машинное обучение - это ветвь искусственного интеллекта, сосредоточенная на анализе данных.",
                "Прогноз погоды: солнечно с температурой 25°C сегодня.",
                "Алгоритмы МО могут изучать закономерности из данных без явного программирования.",
                "Баскетбол - популярный вид спорта, в который играют во всем мире."))
        .build();

ContextPrecisionMetric.ContextPrecisionConfig config = 
        ContextPrecisionMetric.ContextPrecisionConfig.builder()
                .evaluationStrategy(ContextPrecisionMetric.EvaluationStrategy.REFERENCE_BASED)
                .build();

ContextPrecisionMetric metric = new ContextPrecisionMetric(chatClient);
Double score = metric.singleTurnScore(config, sample);
// Результат: ~0.6 (хорошие релевантные фрагменты ранжированы выше)
```

### Параметры конфигурации

|       Параметр       |        Тип         | Обязательный |   По умолчанию   |              Описание              |
|----------------------|--------------------|--------------|------------------|------------------------------------|
| `evaluationStrategy` | EvaluationStrategy | Нет          | Авто-определение | REFERENCE_BASED или RESPONSE_BASED |

**Стратегии оценки:**
- **REFERENCE_BASED**: Использует эталонный ответ как золотой стандарт (предпочтительно, когда доступно)
- **RESPONSE_BASED**: Использует ответ ИИ для оценки релевантности
- **Авто-определение**: Выбирает REFERENCE_BASED, если доступен эталон, иначе RESPONSE_BASED

### Как работает метрика

1. **Оценка релевантности**: Каждый найденный контекстный фрагмент оценивается на релевантность
2. **Вычисление точности**: Для каждой позиции k вычисляется точность@k
3. **Средняя точность**: Вычисляется средняя точность по всем позициям
4. **Финальная оценка**: Возвращает среднюю точность как оценку точности контекста

### Интерпретация результатов

- **0.8-1.0**: Отличная точность, релевантные контексты последовательно ранжированы высоко
- **0.6-0.8**: Хорошая точность, большинство релевантных контекстов ранжированы правильно
- **0.4-0.6**: Умеренная точность, смешанное качество ранжирования
- **0.2-0.4**: Плохая точность, релевантные контексты часто ранжированы низко
- **0.0-0.2**: Очень плохая точность, минимальная эффективность ранжирования

---

## ContextRecall

`ContextRecall` измеряет, сколько утверждений в эталонном ответе можно отнести к найденным контекстам. Эта метрика необходима для оценки полноты найденной информации.

### Когда применять

**Идеальные сценарии:**
- **Всестороннее извлечение информации**: Обеспечение доступности всей необходимой информации
- **Полнота базы знаний**: Проверка полной поддержки эталонных ответов
- **Оценка RAG-системы**: Измерение качества покрытия информации
- **Анализ пробелов извлечения**: Выявление отсутствующей информации в найденных контекстах
- **Академические и исследовательские приложения**: Обеспечение тщательного покрытия информации

**Преимущества:**
- Обеспечивает детальный анализ на уровне утверждений
- Эффективно измеряет полноту информации
- Полезен для выявления пробелов извлечения
- Хорошо работает с фактическим контентом на основе эталонов

**Ограничения:**
- Требует эталонные ответы для оценки
- Может быть строгим в требованиях атрибуции
- Производительность зависит от качества декомпозиции утверждений

### Пример использования

```java
import ai.qa.solutions.metrics.retrieval.ContextRecallMetric;

Sample sample = Sample.builder()
        .userInput("Расскажите о фотосинтезе")
        .reference("Фотосинтез преобразует световую энергию в химическую. " +
                   "Он происходит в хлоропластах. Процесс требует CO₂, воды и солнечного света. " +
                   "Кислород выделяется как побочный продукт.")
        .retrievedContexts(List.of(
                "Фотосинтез - это процесс, при котором растения преобразуют солнечный свет в химическую энергию.",
                "Хлоропласты - это органеллы в растительных клетках, где происходит фотосинтез.",
                "Во время фотосинтеза кислород производится как отходный продукт.",
                "Процесс требует углекислого газа, воды и световой энергии."))
        .build();

ContextRecallMetric.ContextRecallConfig config = 
        ContextRecallMetric.ContextRecallConfig.builder().build();

ContextRecallMetric metric = new ContextRecallMetric(chatClient);
Double score = metric.singleTurnScore(config, sample);
// Результат: ~0.95 (почти все утверждения поддержаны)
```

### Как работает метрика

1. **Декомпозиция утверждений**: Разбивает эталонный ответ на отдельные предложения
2. **Анализ атрибуции**: Оценивает каждое утверждение против найденных контекстов
3. **Классификация поддержки**: Определяет, можно ли каждое утверждение отнести к контекстам
4. **Вычисление отзыва**: Возвращает отношение атрибутируемых утверждений к общему количеству утверждений

### Интерпретация результатов

- **0.9-1.0**: Отличный отзыв, почти вся информация извлекается
- **0.7-0.9**: Хороший отзыв, большинство ключевой информации доступно
- **0.5-0.7**: Умеренный отзыв, отсутствует некоторая важная информация
- **0.3-0.5**: Плохой отзыв, значительные информационные пробелы
- **0.0-0.3**: Очень плохой отзыв, большинство информации не извлекается

---

## Faithfulness

`Faithfulness` измеряет фактическую согласованность между сгенерированным ответом и найденными контекстами. Выявляет галлюцинации и обеспечивает обоснованность ответов в предоставленной информации.

### Когда применять

**Идеальные сценарии:**
- **Обнаружение галлюцинаций**: Выявление фактически неверных или неподдерживаемых утверждений
- **Валидация RAG-системы**: Обеспечение обоснованности ответов в найденных контекстах
- **Контроль качества**: Поддержание фактической точности в ответах ИИ
- **Медицинские/юридические приложения**: Критические домены, требующие фактической точности
- **Новостные и информационные системы**: Обеспечение точного распространения информации

**Преимущества:**
- Обнаруживает как фактические ошибки, так и галлюцинации
- Обеспечивает детальный анализ на уровне утверждений
- Работает с различными типами фактического контента
- Необходим для поддержания надежности ответов

**Ограничения:**
- Требует найденные контексты для оценки
- Может быть чувствительным к качеству декомпозиции утверждений
- Производительность зависит от способностей LLM к фактическому рассуждению

### Пример использования

```java
import ai.qa.solutions.metrics.retrieval.FaithfulnessMetric;

Sample sample = Sample.builder()
        .userInput("Когда был первый Суперкубок?")
        .response("Первый Суперкубок состоялся 15 января 1967 года.")
        .retrievedContexts(List.of(
                "Первый Суперкубок состоялся 15 января 1967 года в Лос-Анджелесском мемориальном колизее."))
        .build();

FaithfulnessMetric metric = new FaithfulnessMetric(chatClient);
Double score = metric.singleTurnScore(sample);
// Результат: 1.0 (полностью верный ответ)
```

### Как работает метрика

1. **Генерация утверждений**: Декомпозирует ответ на атомарные утверждения
2. **Оценка верности**: Проверяет каждое утверждение против найденных контекстов
3. **Назначение вердикта**: Определяет, можно ли утверждения вывести из контекстов
4. **Вычисление оценки**: Возвращает отношение верных утверждений к общему количеству утверждений

### Интерпретация результатов

- **0.9-1.0**: Отличная верность, ответ хорошо обоснован в контекстах
- **0.7-0.9**: Хорошая верность, незначительные несоответствия или пробелы
- **0.5-0.7**: Умеренная верность, присутствуют некоторые неподдерживаемые утверждения
- **0.3-0.5**: Плохая верность, обнаружены значительные галлюцинации
- **0.0-0.3**: Очень плохая верность, ответ в значительной степени неподдерживаемый

---

## NoiseSensitivity

`NoiseSensitivity` измеряет, как часто система совершает ошибки, предоставляя неверные ответы при использовании релевантных или нерелевантных найденных документов. Более низкие оценки указывают на лучшую производительность.

### Когда применять

**Идеальные сценарии:**
- **Тестирование устойчивости**: Оценка поведения системы с шумными результатами извлечения
- **Анализ ошибок**: Понимание того, как нерелевантные контексты влияют на качество ответов
- **Влияние качества извлечения**: Измерение чувствительности к точности извлечения
- **Оптимизация системы**: Улучшение генерации ответов несмотря на шумные входы
- **Мониторинг продакшена**: Обнаружение деградации из-за проблем извлечения

**Преимущества:**
- Измеряет устойчивость системы к шумным входам
- Различает влияния релевантных и нерелевантных контекстов
- Полезен для понимания взаимодействия извлечения-генерации
- Помогает выявить уязвимости системы

**Ограничения:**
- Требует как эталонные ответы, так и найденные контексты
- Сложная метрика с множественными этапами оценки
- Может быть чувствительной к дизайну промптов оценки

### Пример использования

```java
import ai.qa.solutions.metrics.retrieval.NoiseSensitivityMetric;

Sample sample = Sample.builder()
        .userInput("Что вызывает землетрясения?")
        .response("Землетрясения вызываются движением тектонических плит и вулканической активностью.")
        .reference("Землетрясения вызываются движением тектонических плит. " +
                   "Плиты внезапно сдвигаются и высвобождают энергию. Это создает сейсмические волны.")
        .retrievedContexts(List.of(
                "Тектонические плиты - это большие участки земной коры, которые медленно движутся.",
                "Когда тектонические плиты сталкиваются, они могут вызывать землетрясения.",
                "Сейсмические волны - это энергия, высвобождающаяся во время землетрясений.",
                "Лучшее время для посещения Японии - сезон цветения сакуры."))
        .build();

NoiseSensitivityMetric.NoiseSensitivityConfig config = 
        NoiseSensitivityMetric.NoiseSensitivityConfig.builder()
                .mode(NoiseSensitivityMetric.NoiseSensitivityMode.RELEVANT)
                .build();

NoiseSensitivityMetric metric = new NoiseSensitivityMetric(chatClient);
Double score = metric.singleTurnScore(config, sample);
// Результат: ~0.1 (низкая чувствительность, хорошая устойчивость)
```

### Параметры конфигурации

| Параметр |         Тип          | Обязательный | По умолчанию |               Описание               |
|----------|----------------------|--------------|--------------|--------------------------------------|
| `mode`   | NoiseSensitivityMode | Нет          | RELEVANT     | Режим оценки RELEVANT или IRRELEVANT |

**Режимы оценки:**
- **RELEVANT**: Измеряет ошибки от релевантных найденных контекстов
- **IRRELEVANT**: Измеряет ошибки от нерелевантных найденных контекстов

### Как работает метрика

1. **Декомпозиция утверждений**: Разбивает эталон и ответ на атомарные утверждения
2. **Оценка верности**: Оценивает утверждения против контекстов и эталона
3. **Классификация релевантности**: Определяет релевантность контекста на основе эталона
4. **Анализ ошибок**: Выявляет неверные утверждения, атрибутируемые типу контекста
5. **Вычисление чувствительности**: Вычисляет долю ошибок, связанных с контекстом

### Интерпретация результатов

**Для этой метрики лучше более низкие оценки:**
- **0.0-0.1**: Отличная устойчивость, минимальная чувствительность к шуму
- **0.1-0.3**: Хорошая устойчивость, случайные проблемы с чувствительностью
- **0.3-0.5**: Умеренная устойчивость, заметные проблемы с чувствительностью
- **0.5-0.7**: Плохая устойчивость, значительные проблемы с чувствительностью
- **0.7-1.0**: Очень плохая устойчивость, высокая чувствительность к шуму

---

## ResponseRelevancy

`ResponseRelevancy` измеряет релевантность ответа системы относительно пользовательского запроса. Эта метрика оценивает, насколько хорошо ответ соответствует вопросу пользователя, учитывая полноту ответа, отсутствие избыточной информации и присутствие уклончивых (неопределённых) формулировок.

### Когда применять

**Идеальные сценарии:**
- **Оценка качества ответов чат-ботов**: Проверка того, что ответы действительно отвечают на вопросы пользователей
- **Вопросно-ответные системы (Q&A)**: Измерение релевантности ответов на фактологические запросы
- **Диалоговые системы**: Оценка качества многооборотных разговоров
- **Поисковые системы с генерацией ответов**: Проверка соответствия сгенерированных ответов поисковым запросам
- **Виртуальные ассистенты**: Контроль качества ответов на пользовательские команды и вопросы
- **Образовательные платформы**: Оценка релевантности ответов на учебные вопросы

**Преимущества:**
- Обнаруживает уклончивые ответы ("Я не знаю", "Не уверен")
- Выявляет неполные ответы, которые отвечают только на часть вопроса
- Обнаруживает ответы с избыточной нерелевантной информацией
- Работает без эталонного ответа
- Языково-агностический подход (работает с любыми языками)
- Использует семантическое сходство для более точной оценки

**Ограничения:**
- Требует модель эмбеддингов для вычисления семантического сходства
- Может потребоваться несколько вызовов LLM для генерации вопросов
- Оценивает релевантность, но не фактическую правильность ответа
- Может быть чувствительным к качеству генерируемых LLM вопросов

### Пример использования

```java
import ai.qa.solutions.metrics.retrieval.ResponseRelevancyMetric;
import ai.qa.solutions.sample.Sample;

// Пример 1: Полный релевантный ответ
Sample completeSample = Sample.builder()
        .userInput("Где находится Франция и какая её столица?")
        .response("Франция находится в западной Европе, и её столица - Париж.")
        .build();

ResponseRelevancyMetric.ResponseRelevancyConfig config = 
        ResponseRelevancyMetric.ResponseRelevancyConfig.defaultConfig();

ResponseRelevancyMetric metric = new ResponseRelevancyMetric(chatClient, embeddingModel);
Double score = metric.singleTurnScore(config, completeSample);
// Результат: ~0.95 (высокая релевантность, полный ответ)

// Пример 2: Неполный ответ
Sample incompleteSample = Sample.builder()
        .userInput("Где находится Франция и какая её столица?")
        .response("Франция находится в западной Европе.")
        .build();

Double incompleteScore = metric.singleTurnScore(config, incompleteSample);
// Результат: ~0.65 (умеренная релевантность, отвечает только на часть вопроса)

// Пример 3: Уклончивый ответ
Sample noncommittalSample = Sample.builder()
        .userInput("Какая столица Франции?")
        .response("Я не знаю, какая столица Франции.")
        .build();

Double noncommittalScore = metric.singleTurnScore(config, noncommittalSample);
// Результат: 0.0 (нулевая релевантность, уклончивый ответ)
```

### Параметры конфигурации

|      Параметр       | Тип | Обязательный | По умолчанию |                      Описание                      |
|---------------------|-----|--------------|--------------|----------------------------------------------------|
| `numberOfQuestions` | int | Нет          | 3            | Количество вопросов для генерации из ответа (1-10) |

### Как работает метрика

1. **Генерация вопросов**: LLM генерирует N искусственных вопросов на основе ответа (с учётом контекста исходного вопроса)
2. **Определение уклончивости**: Для каждого сгенерированного вопроса определяется, является ли ответ уклончивым
3. **Проверка уклончивости**: Если все вопросы указывают на уклончивый ответ, возвращается оценка 0.0
4. **Вычисление эмбеддингов**: Получает векторные представления исходного вопроса и сгенерированных вопросов
5. **Вычисление сходства**: Вычисляет косинусное сходство между эмбеддингом исходного вопроса и каждым сгенерированным
6. **Агрегация**: Возвращает среднее значение всех показателей сходства как итоговую оценку релевантности

**Ключевая идея метрики:**
- Если ответ релевантен вопросу, то сгенерированные из него вопросы будут семантически похожи на исходный вопрос
- Если ответ не по теме или неполный, сгенерированные вопросы будут отличаться от исходного
- Уклончивые ответы типа "Я не знаю" автоматически получают оценку 0.0

### Интерпретация результатов

- **0.9-1.0**: Отличная релевантность, ответ полностью соответствует вопросу
- **0.7-0.9**: Хорошая релевантность, ответ в основном соответствует вопросу
- **0.5-0.7**: Умеренная релевантность, ответ частично соответствует или содержит дополнительную информацию
- **0.3-0.5**: Низкая релевантность, ответ слабо связан с вопросом или содержит много нерелевантной информации
- **0.0-0.3**: Очень низкая релевантность, ответ не по теме или уклончивый

### Примеры сценариев

**Сценарий 1: Полный релевантный ответ**

```
Вопрос: "Что такое фотосинтез?"
Ответ: "Фотосинтез — это процесс, при котором растения преобразуют световую энергию 
        в химическую энергию. Растения используют солнечный свет, воду и углекислый 
        газ для производства глюкозы и кислорода."
Оценка: ~0.92 (отличная релевантность)
```

**Сценарий 2: Неполный ответ**

```
Вопрос: "Кто изобрёл электрическую лампочку и когда?"
Ответ: "Томас Эдисон изобрёл электрическую лампочку."
Оценка: ~0.65 (умеренная релевантность, отсутствует информация о дате)
```

**Сценарий 3: Ответ не по теме**

```
Вопрос: "Какая столица Франции?"
Ответ: "Великая китайская стена была построена более 2000 лет назад."
Оценка: ~0.15 (очень низкая релевантность, совершенно другая тема)
```

**Сценарий 4: Ответ с избыточной информацией**

```
Вопрос: "Какая столица Франции?"
Ответ: "Столица Франции - Париж. Кстати, вчера я ходил в магазин и купил молоко. 
        Погода была отличная, светило солнце."
Оценка: ~0.55 (сниженная релевантность из-за нерелевантной информации)
```

**Сценарий 5: Уклончивый ответ**

```
Вопрос: "Когда была изобретена электрическая лампочка?"
Ответ: "Не уверен, когда была изобретена электрическая лампочка."
Оценка: 0.0 (уклончивый ответ)
```

---

## Выбор подходящей метрики

|          Случай использования           | Рекомендуемая метрика |                   Почему                   |
|-----------------------------------------|-----------------------|--------------------------------------------|
| Приложения, ориентированные на сущности | ContextEntityRecall   | Измеряет покрытие фактических сущностей    |
| Оптимизация ранжирования извлечения     | ContextPrecision      | Оценивает качество ранжирования контекстов |
| Полнота информации                      | ContextRecall         | Измеряет поддержку эталонных утверждений   |
| Обнаружение галлюцинаций                | Faithfulness          | Выявляет неподдерживаемые утверждения      |
| Тестирование устойчивости системы       | NoiseSensitivity      | Измеряет чувствительность к шумным входам  |
| Оценка релевантности ответов            | ResponseRelevancy     | Измеряет соответствие ответа вопросу       |
| Туристические/туристические системы     | ContextEntityRecall   | Обеспечивает покрытие местоположений/дат   |
| Академические системы знаний            | ContextRecall         | Проверяет всестороннюю информацию          |
| Новостные/информационные системы        | Faithfulness          | Поддерживает фактическую точность          |
| Чат-боты и виртуальные ассистенты       | ResponseRelevancy     | Обеспечивает релевантность диалога         |

---

## Best Practices

### 1. Стратегия выбора метрик

**Для pipeline оценки RAG:**

```java
// Этап 1: Базовое качество извлечения
ContextPrecision precision = new ContextPrecision(chatClient);

// Этап 2: Полнота информации
ContextRecall recall = new ContextRecall(chatClient);

// Этап 3: Качество ответа
Faithfulness faithfulness = new Faithfulness(chatClient);

// Этап 4: Тестирование устойчивости
NoiseSensitivity sensitivity = new NoiseSensitivity(chatClient);
```

### 2. Подготовка примеров

**Необходимые поля для метрик извлечения:**

```java
Sample sample = Sample.builder()
        .userInput("Обязательно для всех метрик")
        .response("Обязательно для Faithfulness и NoiseSensitivity")
        .reference("Обязательно для ContextRecall и NoiseSensitivity")
        .retrievedContexts(List.of("Обязательно для всех метрик извлечения"))
        .build();
```

### 3. Параллельная оценка

```java
// Оценка множественных аспектов одновременно
CompletableFuture<Double> precisionFuture = 
    precisionMetric.singleTurnScoreAsync(precisionConfig, sample);
CompletableFuture<Double> recallFuture = 
    recallMetric.singleTurnScoreAsync(recallConfig, sample);
CompletableFuture<Double> faithfulnessFuture = 
    faithfulnessMetric.singleTurnScoreAsync(sample);

// Ожидание всех результатов
CompletableFuture.allOf(precisionFuture, recallFuture, faithfulnessFuture).join();
```

### 4. Оптимизация контекста

**Для лучшей производительности метрик:**
- Обеспечьте релевантность и хорошее форматирование найденных контекстов
- Поддерживайте согласованное именование сущностей в контекстах
- Обеспечьте достаточное разнообразие контекстов для всесторонней оценки
- Удаляйте дублирующие или почти дублирующие контексты

### 5. Качество эталонов

**Для ContextRecall и NoiseSensitivity:**
- Пишите ясные, фактические эталонные ответы
- Разбивайте сложную информацию на четкие утверждения
- Обеспечьте, чтобы эталоны содержали проверяемые утверждения
- Избегайте субъективного или основанного на мнениях контента

---

## Troubleshooting

### Проблема: Низкий ContextEntityRecall несмотря на хорошие контексты

**Потенциальные причины:**
- Различия в извлечении сущностей между эталоном и контекстами
- Несогласованное именование или форматирование сущностей
- Отсутствие ключевых сущностей в найденных контекстах

**Решения:**
- Стандартизируйте именование сущностей в текстах
- Проверьте правильность работы извлечения сущностей
- Проверьте наличие важных сущностей в контекстах

### Проблема: Нестабильные оценки ContextPrecision

**Потенциальные причины:**
- Неоднозначные критерии релевантности
- Несогласованность оценки LLM
- Смешанное качество в найденных контекстах

**Решения:**
- Используйте оценку на основе эталона, когда возможно
- Обеспечьте ясные, конкретные пользовательские запросы
- Улучшите качество и релевантность контекста

### Проблема: ContextRecall слишком строгий/мягкий

**Потенциальные причины:**
- Декомпозиция утверждений создает слишком тонкую/грубую гранулярность
- Критерии атрибуции слишком строгие/мягкие
- Вариации интерпретации LLM

**Решения:**
- Просмотрите качество декомпозиции утверждений
- Настройте сложность эталонного ответа
- Тестируйте с множественными примерами для проверки согласованности

### Проблема: Ложные срабатывания/пропуски Faithfulness

**Потенциальные причины:**
- Контекст содержит противоречивую информацию
- Проблемы декомпозиции утверждений
- Ограничения фактического рассуждения LLM

**Решения:**
- Обеспечьте фактическую согласованность контекстов
- Проверьте качество сгенерированных утверждений
- Рассмотрите использование множественных оценок LLM

### Проблема: Неожиданные результаты NoiseSensitivity

**Потенциальные причины:**
- Сложная логика оценки
- Выбор режима (RELEVANT vs IRRELEVANT)
- Недостаточное разнообразие контекстов

**Решения:**
- Проверьте соответствие режима оценки случаю использования
- Обеспечьте хорошую смесь релевантных/нерелевантных контекстов
- Проверьте согласованность эталона и ответа

### Проблема: Низкие оценки ResponseRelevancy для правильных ответов

**Потенциальные причины:**
- Ответ содержит избыточную информацию помимо основного
- Стиль ответа значительно отличается от стиля вопроса
- Качество генерируемых LLM вопросов недостаточное
- Модель эмбеддингов не улавливает семантическое сходство

**Решения:**
- Убедитесь, что ответы фокусируются на запрашиваемой информации
- Проверьте качество сгенерированных вопросов в логах
- Попробуйте увеличить numberOfQuestions для более стабильной оценки
- Рассмотрите использование более качественной модели эмбеддингов

### Проблема: ResponseRelevancy не обнаруживает уклончивые ответы

**Потенциальные причины:**
- Уклончивость выражена неявно или в мягкой форме
- LLM неправильно классифицирует ответ как неуклончивый
- Ответ содержит смешанное содержимое (часть уклончиво, часть нет)

**Решения:**
- Проверьте значения noncommittal в сгенерированных вопросах
- Убедитесь, что используется актуальная версия промпта для генерации
- Для смешанных ответов ожидайте промежуточных оценок, а не 0.0

### Проблема: Нестабильные оценки ResponseRelevancy

**Потенциальные причины:**
- Малое количество генерируемых вопросов (numberOfQuestions)
- Вариативность в работе LLM при генерации вопросов
- Нечёткие или многозначные пользовательские вопросы

**Решения:**
- Увеличьте numberOfQuestions до 5-7 для более стабильных оценок
- Тестируйте на множестве примеров для оценки общей согласованности
- Уточните пользовательские вопросы для более однозначной интерпретации

---

## Расширенные примеры

### Пример 1: Полный pipeline оценки RAG

```java
public class RAGEvaluationPipeline {
    
    public RAGEvaluationResult evaluateRAGSystem(Sample sample) {
        // 1. Оценка покрытия сущностей
        ContextEntityRecallMetric entityMetric = new ContextEntityRecallMetric(chatClient);
        Double entityScore = entityMetric.singleTurnScore(
            ContextEntityRecallMetric.ContextEntityRecallConfig.builder().build(), sample);
        
        // 2. Оценка точности извлечения
        ContextPrecisionMetric precisionMetric = new ContextPrecisionMetric(chatClient);
        Double precisionScore = precisionMetric.singleTurnScore(
            ContextPrecisionMetric.ContextPrecisionConfig.builder()
                .evaluationStrategy(ContextPrecisionMetric.EvaluationStrategy.REFERENCE_BASED)
                .build(), sample);
        
        // 3. Оценка полноты информации
        ContextRecallMetric recallMetric = new ContextRecallMetric(chatClient);
        Double recallScore = recallMetric.singleTurnScore(
            ContextRecallMetric.ContextRecallConfig.builder().build(), sample);
        
        // 4. Оценка верности ответа
        FaithfulnessMetric faithfulnessMetric = new FaithfulnessMetric(chatClient);
        Double faithfulnessScore = faithfulnessMetric.singleTurnScore(sample);
        
        // 5. Оценка чувствительности к шуму
        NoiseSensitivityMetric sensitivityMetric = new NoiseSensitivityMetric(chatClient);
        Double sensitivityScore = sensitivityMetric.singleTurnScore(
            NoiseSensitivityMetric.NoiseSensitivityConfig.builder()
                .mode(NoiseSensitivityMetric.NoiseSensitivityMode.RELEVANT)
                .build(), sample);
        
        // 6. Оценка релевантности ответа
        ResponseRelevancyMetric relevancyMetric = new ResponseRelevancyMetric(chatClient, embeddingModel);
        Double relevancyScore = relevancyMetric.singleTurnScore(
            ResponseRelevancyMetric.ResponseRelevancyConfig.defaultConfig(), sample);
        
        return new RAGEvaluationResult(
            entityScore, precisionScore, recallScore, 
            faithfulnessScore, sensitivityScore, relevancyScore);
    }
}
```

### Пример 2: Сравнение стратегий извлечения

```java
public class RetrievalComparison {
    
    public void compareRetrievalStrategies() {
        String query = "Что такое машинное обучение?";
        String reference = "Машинное обучение - это ветвь ИИ, которая использует алгоритмы для обучения на данных.";
        
        // Стратегия A: Извлечение на основе ключевых слов
        List<String> keywordContexts = List.of(
            "Алгоритмы машинного обучения изучают закономерности из данных.",
            "ИИ включает различные техники, включая МО.",
            "Наука о данных использует статистические методы для анализа."
        );
        
        // Стратегия B: Семантическое извлечение
        List<String> semanticContexts = List.of(
            "Машинное обучение - это подмножество искусственного интеллекта, сосредоточенное на обучении на основе данных.",
            "Алгоритмы МО автоматически улучшают производительность через опыт.",
            "Контролируемое и неконтролируемое обучение - основные парадигмы МО."
        );
        
        Sample sampleA = Sample.builder()
            .userInput(query).reference(reference)
            .retrievedContexts(keywordContexts).build();
            
        Sample sampleB = Sample.builder()
            .userInput(query).reference(reference)
            .retrievedContexts(semanticContexts).build();
        
        // Сравнение с использованием множественных метрик
        ContextRecallMetric recallMetric = new ContextRecallMetric(chatClient);
        ContextPrecisionMetric precisionMetric = new ContextPrecisionMetric(chatClient);
        
        // Оценка обеих стратегий
        Map<String, Double> strategyAScores = Map.of(
            "recall", recallMetric.singleTurnScore(
                ContextRecallMetric.ContextRecallConfig.builder().build(), sampleA),
            "precision", precisionMetric.singleTurnScore(
                ContextPrecisionMetric.ContextPrecisionConfig.builder().build(), sampleA)
        );
        
        Map<String, Double> strategyBScores = Map.of(
            "recall", recallMetric.singleTurnScore(
                ContextRecallMetric.ContextRecallConfig.builder().build(), sampleB),
            "precision", precisionMetric.singleTurnScore(
                ContextPrecisionMetric.ContextPrecisionConfig.builder().build(), sampleB)
        );
        
        System.out.println("Стратегия на основе ключевых слов: " + strategyAScores);
        System.out.println("Семантическая стратегия: " + strategyBScores);
    }
}
```

### Пример 3: Доменно-специфическая оценка

```java
public class DomainSpecificEvaluation {
    
    // Оценка туристического домена
    public void evaluateTourismRAG() {
        Sample tourismSample = Sample.builder()
            .userInput("Расскажите о посещении Лувра")
            .reference("Лувр расположен в Париже, Франция. " +
                      "В нем находится Мона Лиза, написанная Леонардо да Винчи. " +
                      "Музей открыт со вторника по воскресенье.")
            .retrievedContexts(List.of(
                "Лувр - один из крупнейших художественных музеев мира, расположенный в Париже.",
                "Мона Лиза Леонардо да Винчи - самая известная картина в Лувре.",
                "Музей закрыт по понедельникам и открыт со вторника по воскресенье.",
                "Рекомендуется предварительное бронирование в пиковый туристический сезон."))
            .build();
        
        // Фокус на покрытии сущностей для туризма
        ContextEntityRecallMetric entityMetric = new ContextEntityRecallMetric(chatClient);
        Double entityScore = entityMetric.singleTurnScore(
            ContextEntityRecallMetric.ContextEntityRecallConfig.builder().build(), 
            tourismSample);
        
        System.out.println("Покрытие туристических сущностей: " + entityScore);
    }
}
```

### Пример 4: Оценка качества ответов чат-бота

```java
public class ChatbotEvaluation {
    
    // Оценка релевантности ответов чат-бота
    public void evaluateChatbotResponses() {
        ResponseRelevancyMetric relevancyMetric = new ResponseRelevancyMetric(chatClient, embeddingModel);
        
        // Тест 1: Полный релевантный ответ
        Sample fullAnswerSample = Sample.builder()
            .userInput("Какие часы работы вашего магазина?")
            .response("Наш магазин работает с понедельника по пятницу с 9:00 до 18:00, " +
                     "в субботу с 10:00 до 16:00, воскресенье - выходной.")
            .build();
        
        Double fullScore = relevancyMetric.singleTurnScore(
            ResponseRelevancyMetric.ResponseRelevancyConfig.defaultConfig(), 
            fullAnswerSample);
        System.out.println("Полный ответ: " + fullScore); // Ожидается: ~0.90-0.95
        
        // Тест 2: Неполный ответ
        Sample incompleteAnswerSample = Sample.builder()
            .userInput("Какие часы работы вашего магазина?")
            .response("Наш магазин работает с понедельника по пятницу с 9:00 до 18:00.")
            .build();
        
        Double incompleteScore = relevancyMetric.singleTurnScore(
            ResponseRelevancyMetric.ResponseRelevancyConfig.defaultConfig(), 
            incompleteAnswerSample);
        System.out.println("Неполный ответ: " + incompleteScore); // Ожидается: ~0.65-0.75
        
        // Тест 3: Уклончивый ответ
        Sample noncommittalSample = Sample.builder()
            .userInput("Какие часы работы вашего магазина?")
            .response("Я не уверен в точных часах работы нашего магазина.")
            .build();
        
        Double noncommittalScore = relevancyMetric.singleTurnScore(
            ResponseRelevancyMetric.ResponseRelevancyConfig.defaultConfig(), 
            noncommittalSample);
        System.out.println("Уклончивый ответ: " + noncommittalScore); // Ожидается: 0.0
        
        // Тест 4: Ответ с избыточной информацией
        Sample redundantSample = Sample.builder()
            .userInput("Какие часы работы вашего магазина?")
            .response("Наш магазин работает с 9:00 до 18:00. " +
                     "Кстати, у нас сейчас распродажа. " +
                     "Погода сегодня отличная, не правда ли?")
            .build();
        
        Double redundantScore = relevancyMetric.singleTurnScore(
            ResponseRelevancyMetric.ResponseRelevancyConfig.defaultConfig(), 
            redundantSample);
        System.out.println("Ответ с избыточной информацией: " + redundantScore); // Ожидается: ~0.50-0.65
        
        // Анализ результатов
        if (fullScore > 0.85 && noncommittalScore < 0.1) {
            System.out.println("✓ Чат-бот правильно отвечает на прямые вопросы");
        }
        if (incompleteScore < fullScore) {
            System.out.println("✓ Метрика корректно выявляет неполные ответы");
        }
    }
    
    // Оценка с настройкой количества вопросов
    public void evaluateWithCustomConfig() {
        ResponseRelevancyMetric relevancyMetric = new ResponseRelevancyMetric(chatClient, embeddingModel);
        
        Sample sample = Sample.builder()
            .userInput("Объясните, что такое машинное обучение")
            .response("Машинное обучение - это раздел искусственного интеллекта, " +
                     "который позволяет компьютерам учиться на данных без явного программирования. " +
                     "Алгоритмы МО выявляют закономерности в данных и используют их для прогнозирования.")
            .build();
        
        // Используем больше вопросов для более стабильной оценки
        ResponseRelevancyMetric.ResponseRelevancyConfig config = 
            ResponseRelevancyMetric.ResponseRelevancyConfig.builder()
                .numberOfQuestions(5)
                .build();
        
        Double score = relevancyMetric.singleTurnScore(config, sample);
        System.out.println("Оценка релевантности (5 вопросов): " + score);
    }
}
```

