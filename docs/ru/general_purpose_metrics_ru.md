# General Purpose Metrics (Универсальные метрики)

Универсальные метрики оценки предназначены для измерения качества ответов AI-систем в различных сценариях. Эти метрики не привязаны к конкретной задаче и могут применяться для оценки любых типов генерируемого контента.

## Содержание

- [Когда использовать](#когда-использовать)
- [AspectCritic](#aspectcritic)
- [SimpleCriteriaScore](#simplecriteriascore)
- [RubricsScore](#rubricsscore)
- [Параллельная оценка](#параллельная-оценка-нескольких-метрик)
- [Выбор метрики](#выбор-подходящей-метрики)
- [Best Practices](#best-practices)
- [Troubleshooting](#troubleshooting)
- [Расширенные примеры](#расширенные-примеры)

## Когда использовать

**Используйте эти метрики когда:**
- Необходимо оценить общее качество ответов без специфических требований к домену
- Нужна быстрая проверка соответствия ответов заданным критериям
- Требуется бинарная оценка (соответствует/не соответствует)
- Необходима оценка по заранее определённой шкале или рубрикам
- Нужно проверить ответы на безопасность, корректность или другие аспекты
- Требуется гибкая настройка критериев оценки под конкретную задачу

**Не используйте эти метрики когда:**
- Нужны специализированные метрики для конкретных задач (RAG, кодогенерация, суммаризация)
- Требуется оценка технических аспектов (латентность, токены, стоимость)
- Необходима оценка на основе внешних источников данных или контекста

---

## AspectCritic

`AspectCritic` — это бинарная метрика оценки, которая проверяет соответствие ответа AI-системы заданному критерию. Метрика возвращает `1.0` (соответствует) или `0.0` (не соответствует).

### Когда применять

**Идеальные сценарии:**
- **Проверка безопасности контента**: определение вредоносной, токсичной или неприемлемой информации
- **Валидация корректности**: проверка фактической точности и достоверности ответов
- **Контроль качества**: оценка соблюдения корпоративных стандартов и политик
- **Compliance проверки**: соответствие регуляторным требованиям и юридическим нормам
- **Фильтрация контента**: отсев неподходящих ответов в production pipeline

**Преимущества:**
- Простая интерпретация результатов (бинарная оценка)
- Настраиваемый уровень строгости оценки
- Высокая скорость выполнения
- Подходит для автоматической фильтрации

**Ограничения:**
- Не показывает степень соответствия (только да/нет)
- Требует чёткого определения критерия
- Может быть слишком жёсткой для пограничных случаев

### Пример использования

```java
import ai.qa.solutions.metrics.general.AspectCriticMetric;
import ai.qa.solutions.sample.Sample;

Sample sample = Sample.builder()
    .userInput("Как защитить компьютер от вирусов?")
    .response("Установите антивирус, регулярно обновляйте систему, "
        + "не открывайте подозрительные ссылки и делайте резервные копии данных.")
    .build();

AspectCriticMetric.AspectCriticConfig config = 
    AspectCriticMetric.AspectCriticConfig.builder()
        .definition("Содержит ли ответ вредоносную или опасную информацию?")
        .strictness(4) // 1=мягко, 5=очень строго
        .build();

AspectCriticMetric metric = new AspectCriticMetric(chatClient);
Double score = metric.singleTurnScore(config, sample);
// Результат: 0.0 (безопасный контент)
```

### Параметры конфигурации

|   Параметр   |   Тип   | Обязательный | По умолчанию |             Описание              |
|--------------|---------|--------------|--------------|-----------------------------------|
| `definition` | String  | Да           | -            | Критерий оценки в свободной форме |
| `strictness` | Integer | Нет          | 3            | Уровень строгости оценки (1-5)    |

**Уровни строгости:**
- **1-2**: Мягкая оценка, допускает неточности
- **3**: Сбалансированная оценка (рекомендуется)
- **4-5**: Строгая оценка, требует полного соответствия

### Как работает метрика

AspectCritic использует LLM для анализа ответа по заданному критерию:

1. **Анализ контекста**: Учитывается пользовательский запрос и полученный ответ
2. **Применение критерия**: LLM оценивает соответствие ответа заданному определению
3. **Учёт строгости**: Применяется настроенный уровень строгости оценки
4. **Вынесение вердикта**: Возвращается бинарное решение с обоснованием

### Асинхронное выполнение

```java
CompletableFuture<Double> futureScore = 
    metric.singleTurnScoreAsync(config, sample);
Double score = futureScore.get(); // Неблокирующая оценка
```

---

## SimpleCriteriaScore

`SimpleCriteriaScore` — это метрика количественной оценки, которая присваивает числовое значение ответу на основе заданного критерия. В отличие от бинарной AspectCritic, эта метрика показывает степень соответствия.

### Когда применять

**Идеальные сценарии:**
- **Оценка качества объяснений**: насколько полно и понятно объяснена концепция
- **Измерение релевантности**: степень соответствия ответа запросу
- **Оценка стиля и тона**: соответствие корпоративному стилю коммуникации
- **Ранжирование ответов**: выбор лучшего из нескольких вариантов
- **A/B тестирование**: сравнение версий промптов или моделей

**Преимущества:**
- Гранулярная оценка качества
- Гибкая настройка диапазона баллов
- Подходит для ранжирования и сравнения
- Показывает тренды улучшения/ухудшения

**Ограничения:**
- Субъективность числовой оценки
- Требует хорошо определённого критерия
- Может быть менее стабильной, чем бинарная оценка

### Пример использования

```java
import ai.qa.solutions.metrics.general.SimpleCriteriaScoreMetric;

Sample sample = Sample.builder()
    .userInput("Что такое искусственный интеллект?")
    .response("Искусственный интеллект — это область информатики, которая "
        + "создаёт системы, способные выполнять задачи, требующие "
        + "человеческого интеллекта: обучение, рассуждение и восприятие.")
    .reference("ИИ — технология, имитирующая человеческое мышление.")
    .build();

SimpleCriteriaScoreMetric.SimpleCriteriaConfig config = 
    SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
        .definition("Оцените полноту и ясность объяснения")
        .minScore(1.0)
        .maxScore(5.0)
        .build();

SimpleCriteriaScoreMetric metric = new SimpleCriteriaScoreMetric(chatClient);
Double score = metric.singleTurnScore(config, sample);
// Результат: 4.5 (высокое качество объяснения)
```

### Параметры конфигурации

|   Параметр   |  Тип   | Обязательный | По умолчанию |                  Описание                   |
|--------------|--------|--------------|--------------|---------------------------------------------|
| `definition` | String | Да           | -            | Критерий оценки, описывающий что измеряется |
| `minScore`   | Double | Нет          | 0.0          | Минимальное значение шкалы                  |
| `maxScore`   | Double | Нет          | 5.0          | Максимальное значение шкалы                 |

**Рекомендуемые диапазоны:**
- **0-1**: Для нормализованных метрик и вероятностей
- **1-5**: Для общей оценки качества (стандарт)
- **1-10**: Для более детальной градации
- **0-100**: Для процентных оценок

### Интерпретация результатов

Для шкалы 1-5 (стандартной):
- **1.0-2.0**: Низкое качество, требуется значительная доработка
- **2.0-3.0**: Удовлетворительно, есть существенные недостатки
- **3.0-4.0**: Хорошо, незначительные улучшения желательны
- **4.0-5.0**: Отлично, высокое качество ответа

---

## RubricsScore

`RubricsScore` — это метрика с детализированными критериями оценки. Вместо одного критерия используется набор рубрик, где каждый уровень баллов имеет подробное описание.

### Когда применять

**Идеальные сценарии:**
- **Оценка эссе и текстов**: когда есть чёткие критерии качества для каждого уровня
- **Образовательные системы**: оценка ответов учащихся по стандартизированным рубрикам
- **Контроль качества документации**: проверка соответствия стандартам написания
- **Код-ревью**: оценка качества кода по заданным критериям
- **Креативный контент**: оценка оригинальности, стиля, структуры

**Преимущества:**
- Максимальная прозрачность оценки
- Согласованность между разными оценками
- Подробная обратная связь о качестве
- Легко адаптируется под специфические требования

**Ограничения:**
- Требует времени на создание рубрик
- Сложнее в настройке, чем другие метрики
- Может быть избыточной для простых задач

### Пример использования

```java
import ai.qa.solutions.metrics.general.RubricsScoreMetric;

Sample sample = Sample.builder()
    .userInput("Объясните процесс фотосинтеза")
    .response("Фотосинтез — процесс, при котором растения преобразуют "
        + "световую энергию в химическую. В хлоропластах хлорофилл "
        + "поглощает свет, расщепляя воду и выделяя кислород. "
        + "CO₂ превращается в глюкозу в цикле Кальвина.")
    .reference("Фотосинтез - образование органических веществ "
        + "из CO₂ и воды с использованием света.")
    .build();

RubricsScoreMetric.RubricsConfig config = 
    RubricsScoreMetric.RubricsConfig.builder()
        .rubric("score1_description", 
            "Полностью неверная или нерелевантная информация")
        .rubric("score2_description", 
            "Базовое понимание с существенными пробелами")
        .rubric("score3_description", 
            "Общее понимание, отсутствуют важные детали")
        .rubric("score4_description", 
            "Хорошее понимание с основными этапами и компонентами")
        .rubric("score5_description", 
            "Отличное объяснение с научными деталями и примерами")
        .build();

RubricsScoreMetric metric = new RubricsScoreMetric(chatClient);
Double score = metric.singleTurnScore(config, sample);
// Результат: 4.0 (хорошее понимание темы)
```

### Параметры конфигурации

| Параметр  |         Тип         | Обязательный |              Описание              |
|-----------|---------------------|--------------|------------------------------------|
| `rubrics` | Map<String, String> | Да           | Описания для каждого уровня баллов |

**Требования к ключам:** Должны быть в формате `score1_description`, `score2_description`, и т.д.

**Рекомендации:** Используйте 3-5 уровней для оптимального баланса детализации и простоты

### Создание эффективных рубрик

#### Принципы составления

**1. Конкретность**

Описывайте наблюдаемые характеристики, а не абстрактные понятия:
- ❌ Плохо: "Хороший ответ"
- ✅ Хорошо: "Ответ содержит определение, 2-3 примера и объяснение причинно-следственных связей"

**2. Прогрессия**

Каждый уровень должен логично развивать предыдущий:
- Level 1: Базовое упоминание темы
- Level 2: Определение + 1 пример
- Level 3: Определение + примеры + контекст
- Level 4: Всё выше + анализ
- Level 5: Всё выше + синтез + нюансы

**3. Измеримость**

Используйте количественные индикаторы где возможно:
- "Содержит 3+ релевантных примера"
- "Объясняет минимум 2 причинно-следственные связи"

**4. Согласованность**

Используйте единую терминологию со схемой Sample:
- Если Sample использует `reference`, не пишите "ground truth" в рубриках

#### Пример полного набора рубрик

**Для оценки кода:**

```java
RubricsScoreMetric.RubricsConfig config = 
    RubricsScoreMetric.RubricsConfig.builder()
        .rubric("score1_description", 
            "Код не работает или содержит критические ошибки синтаксиса/логики")
        .rubric("score2_description", 
            "Код работает, но неэффективен, есть очевидные проблемы производительности")
        .rubric("score3_description", 
            "Код работает корректно, базовая оптимизация, читаемость средняя")
        .rubric("score4_description", 
            "Код эффективен, хорошо структурирован, есть комментарии, следует best practices")
        .rubric("score5_description", 
            "Отличный код: оптимальная сложность O(n), SOLID принципы, "
            + "полная документация, обработка edge cases, покрытие тестами")
        .build();
```

---

## Параллельная оценка нескольких метрик

Все метрики поддерживают асинхронное выполнение через CompletableFuture, что позволяет эффективно оценивать один ответ по нескольким критериям одновременно.

### Пример комплексной оценки

```java
Sample sample = Sample.builder()
    .userInput("Расскажите о глобальном потеплении")
    .response("Глобальное потепление — повышение температуры планеты "
        + "из-за парниковых газов от деятельности человека...")
    .reference("Глобальное потепление - увеличение температуры Земли "
        + "из-за парникового эффекта.")
    .build();

// Конфигурация метрик
var aspectConfig = AspectCriticMetric.AspectCriticConfig.builder()
    .definition("Содержит ли ответ научно достоверную информацию?")
    .build();

var criteriaConfig = SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
    .definition("Оцените полноту и ясность объяснения")
    .minScore(1.0)
    .maxScore(5.0)
    .build();

var rubricsConfig = RubricsScoreMetric.RubricsConfig.builder()
    .rubric("score1_description", "Неверная информация")
    .rubric("score3_description", "Базовое понимание")
    .rubric("score5_description", "Экспертное объяснение с деталями")
    .build();

// Параллельное выполнение
CompletableFuture<Double> aspect = 
    aspectMetric.singleTurnScoreAsync(aspectConfig, sample);
CompletableFuture<Double> criteria = 
    criteriaMetric.singleTurnScoreAsync(criteriaConfig, sample);
CompletableFuture<Double> rubrics = 
    rubricsMetric.singleTurnScoreAsync(rubricsConfig, sample);

// Ожидание всех результатов
CompletableFuture.allOf(aspect, criteria, rubrics).join();

System.out.println("Достоверность: " + aspect.join());  // 1.0
System.out.println("Качество: " + criteria.join());     // 4.2
System.out.println("По рубрикам: " + rubrics.join());   // 4.0
```

---

## Выбор подходящей метрики

|            Сценарий            | Рекомендуемая метрика |             Почему             |
|--------------------------------|-----------------------|--------------------------------|
| Проверка безопасности контента | AspectCritic          | Нужна простая проверка да/нет  |
| Фильтрация токсичного контента | AspectCritic          | Быстрая бинарная классификация |
| Сравнение качества промптов    | SimpleCriteriaScore   | Показывает степень улучшения   |
| Ранжирование вариантов ответов | SimpleCriteriaScore   | Числовая оценка для сортировки |
| Оценка учебных работ           | RubricsScore          | Детальная обратная связь       |
| Контроль качества документации | RubricsScore          | Стандартизированные критерии   |
| Быстрая валидация в production | AspectCritic          | Минимальная латентность        |
| Детальный анализ качества      | RubricsScore          | Максимум информации            |

---

## Best Practices

### 1. Формулирование критериев

**Для AspectCritic:**
- Используйте вопросительную форму: "Содержит ли...?", "Является ли...?"
- Будьте специфичны: вместо "хороший ответ" → "фактически точный ответ"
- Избегайте двойного отрицания

```java
// ✅ Хорошо
.definition("Содержит ли ответ инструкции по незаконной деятельности?")
.definition("Является ли информация фактически точной и проверяемой?")

// ❌ Плохо
.definition("Ответ не должен не содержать ошибок") // двойное отрицание
.definition("Хороший ответ") // слишком расплывчато
```

**Для SimpleCriteriaScore:**
- Опишите что именно оценивается: "полноту объяснения", "соответствие тону"
- Укажите диапазон явно в описании критерия
- Избегайте субъективных терминов без пояснений

**Для RubricsScore:**
- Начинайте каждую рубрику с уровня требований
- Используйте действительные глаголы: "содержит", "объясняет", "демонстрирует"
- Добавляйте конкретные индикаторы качества

### 2. Настройка строгости (AspectCritic)

```java
// Для контента, где допустимы неточности (творческие тексты)
.strictness(2)

// Для сбалансированной оценки (общие случаи)
.strictness(3)

// Для критически важных проверок (безопасность, compliance)
.strictness(5)
```

### 3. Оптимизация производительности

- Используйте AspectCritic для первичной фильтрации (быстрая)
- Применяйте детальные метрики только к прошедшим фильтрацию ответам
- Кэшируйте результаты для идентичных конфигураций
- Используйте batch-оценку через CompletableFuture для больших датасетов

### 4. Интерпретация результатов

- Устанавливайте пороговые значения на основе статистики по вашим данным
- Логируйте не только баллы, но и reasoning из Response DTO
- Мониторьте распределение баллов для выявления проблем с метриками
- Сравнивайте результаты разных метрик для валидации

---

## Troubleshooting

### Проблема: Нестабильные оценки между запусками

**Решение:**
- Установите temperature=0 в настройках ChatClient для детерминированности
- Увеличьте строгость критериев
- Используйте более конкретные формулировки в определениях

### Проблема: Все оценки слишком высокие/низкие

**Решение:**
- Пересмотрите формулировку критериев (возможно, слишком мягкая/жёсткая)
- Для SimpleCriteriaScore: проверьте диапазон баллов
- Для RubricsScore: убедитесь, что рубрики покрывают весь спектр качества

### Проблема: Метрика не различает хорошие и плохие ответы

**Решение:**
- Добавьте reference ответ в Sample для сравнения
- Используйте RubricsScore вместо SimpleCriteriaScore для большей детализации
- Проверьте, что критерий действительно релевантен для вашей задачи

---

## Расширенные примеры

### Пример 1: Мультиязычная оценка

```java
// Критерии могут быть на любом языке, который поддерживает LLM
public class MultilingualEvaluation {
    
    public Map<String, Double> evaluateMultilingual(Sample sample) {
        // Русский
        var ruConfig = AspectCriticMetric.AspectCriticConfig.builder()
            .definition("Содержит ли ответ грамматические ошибки?")
            .build();
        
        // Английский
        var enConfig = AspectCriticMetric.AspectCriticConfig.builder()
            .definition("Does the response contain grammatical errors?")
            .build();
        
        return Map.of(
            "ru", aspectMetric.singleTurnScore(ruConfig, sample),
            "en", aspectMetric.singleTurnScore(enConfig, sample)
        );
    }
}
```

### Пример 2: Доменно-специфичная оценка

```java
// Медицинская информация
var medicalConfig = AspectCriticMetric.AspectCriticConfig.builder()
    .definition("Содержит ли ответ медицинские рекомендации "
        + "без предупреждения о необходимости консультации врача?")
    .strictness(5) // Максимальная строгость для безопасности
    .build();

// Финансовые советы
var financialConfig = SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
    .definition("Оцените полноту раскрытия рисков и дисклеймеров")
    .minScore(0.0)
    .maxScore(10.0)
    .build();
```

### Пример 3: A/B тестирование промптов

```java
List<Sample> variantA = generateResponses(promptA);
List<Sample> variantB = generateResponses(promptB);

var config = SimpleCriteriaScoreMetric.SimpleCriteriaConfig.builder()
    .definition("Оцените релевантность и полноту ответа")
    .minScore(1.0)
    .maxScore(5.0)
    .build();

double avgScoreA = variantA.stream()
    .mapToDouble(s -> metric.singleTurnScore(config, s))
    .average()
    .orElse(0.0);

double avgScoreB = variantB.stream()
    .mapToDouble(s -> metric.singleTurnScore(config, s))
    .average()
    .orElse(0.0);

System.out.println("Промпт A: " + avgScoreA);
System.out.println("Промпт B: " + avgScoreB);
System.out.println("Улучшение: " + ((avgScoreB - avgScoreA) / avgScoreA * 100) + "%");
```

