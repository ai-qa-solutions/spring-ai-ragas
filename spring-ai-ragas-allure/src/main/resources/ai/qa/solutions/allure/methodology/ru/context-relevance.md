# Метрика Context Relevance (стиль NVIDIA)

## Глоссарий

- **Контекст** — фрагмент текста, извлечённый из базы знаний или хранилища документов
- **Вопрос пользователя** — входной запрос от пользователя
- **Оценка релевантности** — оценка того, насколько контекст помогает ответить на вопрос
- **Сырая оценка** — оценка по шкале 0-2 до нормализации
- **Нормализованная оценка** — оценка по шкале 0-1 после деления сырой оценки на 2

## Описание

Метрика оценивает, релевантны ли извлечённые контексты вопросу пользователя. Она использует шкалу оценки 0-2, которая затем нормализуется к 0-1.

Это метрика в стиле NVIDIA, обеспечивающая детальную оценку релевантности:

- **0** — Нерелевантен: Контекст не содержит информации для ответа на вопрос
- **1** — Частично релевантен: Контекст содержит некоторую релевантную информацию, но может быть неполным
- **2** — Полностью релевантен: Контекст содержит исчерпывающую информацию для ответа на вопрос

## Пример

**Вопрос пользователя:** "Что такое машинное обучение и как оно работает?"

**Извлечённые контексты:**

1. "Машинное обучение — это подраздел искусственного интеллекта, позволяющий системам автоматически обучаться и совершенствоваться на основе опыта без явного программирования."

2. "Прогноз погоды обещает переменную облачность завтра."

**Анализ:**

- Контекст 1: Сырая оценка = 2 (полностью релевантен), Нормализованная = 1.0
- Контекст 2: Сырая оценка = 0 (нерелевантен), Нормализованная = 0.0
- Среднее: (1.0 + 0.0) / 2 = 0.5

**Оценка:** **0.5 (50%)** — Смешанная релевантность

## Интерпретация оценки

| Оценка  |                            Значение                             |
|---------|-----------------------------------------------------------------|
| 90-100% | Отлично — все контексты высоко релевантны                       |
| 70-89%  | Хорошо — большинство контекстов содержат релевантную информацию |
| 50-69%  | Средне — смешанная релевантность контекстов                     |
| 0-49%   | Плохо — контексты в основном нерелевантны                       |

## Алгоритм

1. **Оценка каждого контекста** — LLM оценивает каждый контекст по шкале 0-2
2. **Нормализация оценок** — Деление каждой сырой оценки на 2 для получения диапазона 0-1
3. **Усреднение оценок** — Вычисление среднего по всем оценкам контекстов

### Расчёт оценки

```
Для каждого контекста:
  нормализованная_оценка = сырая_оценка / 2.0

Итоговая оценка = среднее(нормализованные_оценки)
```

## Формула

```
Context Relevance = (1/N) * sum(score_i / 2)

где:
  N = количество контекстов
  score_i = сырая оценка (0-2) для контекста i
```

## Конфигурация

```java
ContextRelevanceConfig config = ContextRelevanceConfig.builder()
    .temperature(0.1)  // Низкая температура для стабильных результатов
    .build();
```

|   Параметр    |   Тип    | По умолчанию |          Описание          |
|---------------|----------|--------------|----------------------------|
| `temperature` | `double` | `0.1`        | Температура LLM для оценки |
| `models`      | `List`   | все          | ID моделей для оценки      |

## Требования к Sample

|        Поле         | Обязательно |           Описание            |
|---------------------|-------------|-------------------------------|
| `userInput`         | Да          | Вопрос пользователя           |
| `retrievedContexts` | Да          | Список извлечённых контекстов |

## Сценарии использования

- Оценка качества извлечения в RAG-системах
- Тестирование систем поиска документов
- Оценка релевантности результатов поиска
- Валидация извлечения из базы знаний

## Ссылки

- [NVIDIA RAG Evaluation](https://developer.nvidia.com/blog/evaluating-retrieval-augmented-generation-pipelines/)
- [Документация RAGAS](https://docs.ragas.io/)

