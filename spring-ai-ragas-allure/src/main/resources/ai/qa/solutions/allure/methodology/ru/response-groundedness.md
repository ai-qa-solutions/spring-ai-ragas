# Метрика Response Groundedness (стиль NVIDIA)

## Глоссарий

- **Ответ** — сгенерированный ИИ ответ для оценки
- **Контекст** — извлечённые фрагменты текста, использованные для формирования ответа
- **Обоснованный** — информация, которую можно найти или вывести из контекста
- **Сырая оценка** — оценка по шкале 0-2 до нормализации
- **Нормализованная оценка** — оценка по шкале 0-1 после деления сырой оценки на 2
- **Эвристические сокращения** — быстрые проверки для обхода LLM оценки в очевидных случаях

## Описание

Метрика оценивает, обоснован ли ответ ИИ извлечёнными контекстами. Она использует шкалу оценки 0-2, которая затем нормализуется к 0-1.

Это метрика в стиле NVIDIA, обеспечивающая:

- **0** — Необоснован: Ответ содержит значительную информацию, отсутствующую в контексте
- **1** — Частично обоснован: Ответ частично подтверждается контекстом
- **2** — Полностью обоснован: Ответ полностью подтверждается контекстом

Метрика поддерживает опциональные эвристические сокращения:
- Точное совпадение: Если ответ точно совпадает с контекстом → возвращает 1.0 немедленно
- Содержание: Если ответ содержится в контексте → возвращает 1.0 немедленно

## Пример

**Ответ:** "Москва — столица России с населением около 12 миллионов человек."

**Контекст:** "Москва является столицей и крупнейшим городом России. Она расположена на реке Москва."

**Анализ:**
- Ответ утверждает, что Москва — столица России — обосновано
- Ответ упоминает население 12 миллионов — необосновано (нет в контексте)
- Сырая оценка: 1 (частично обоснован)
- Нормализованная: 1/2 = 0.5

**Оценка:** **0.5 (50%)** — Частично обоснован

## Интерпретация оценки

| Оценка  |                      Значение                       |
|---------|-----------------------------------------------------|
| 90-100% | Отлично — ответ полностью обоснован                 |
| 70-89%  | Хорошо — ответ в основном обоснован                 |
| 50-69%  | Средне — ответ частично обоснован                   |
| 0-49%   | Плохо — ответ содержит неподтверждённые утверждения |

## Алгоритм

1. **Применение эвристик** (если включено)
   - Проверка точного совпадения между ответом и контекстом
   - Проверка полного содержания ответа в контексте
   - Если совпадение найдено → вернуть 1.0
2. **Оценка обоснованности** — LLM оценивает ответ по шкале 0-2
3. **Нормализация оценки** — Деление сырой оценки на 2

### Расчёт оценки

```
Если эвристика сработала:
  Оценка = 1.0

Иначе:
  Оценка = сырая_оценка / 2.0
```

## Формула

```
Response Groundedness = сырая_оценка / 2

где:
  сырая_оценка = LLM оценка (0, 1 или 2)
```

## Конфигурация

```java
ResponseGroundednessConfig config = ResponseGroundednessConfig.builder()
    .useHeuristicShortcuts(true)  // Включить быстрые проверки (по умолчанию: true)
    .temperature(0.1)              // Температура LLM (по умолчанию: 0.1)
    .build();
```

|        Параметр         |    Тип    | По умолчанию |             Описание              |
|-------------------------|-----------|--------------|-----------------------------------|
| `useHeuristicShortcuts` | `boolean` | `true`       | Включить эвристические сокращения |
| `temperature`           | `double`  | `0.1`        | Температура LLM для оценки        |
| `models`                | `List`    | все          | ID моделей для оценки             |

## Требования к Sample

|        Поле         | Обязательно |           Описание            |
|---------------------|-------------|-------------------------------|
| `response`          | Да          | Ответ ИИ для оценки           |
| `retrievedContexts` | Да          | Список извлечённых контекстов |

## Сценарии использования

- Оценка качества ответов в RAG-системах
- Тестирование на галлюцинации в ответах ИИ
- Валидация достоверности ответа относительно исходного материала
- Измерение обоснованности в системах вопрос-ответ по документам

## Сравнение с Faithfulness

|          Аспект          |    ResponseGroundedness    |         Faithfulness         |
|--------------------------|----------------------------|------------------------------|
| Шкала оценки             | 0-2, нормализованная к 0-1 | Бинарная по каждому claim    |
| Гранулярность            | Весь ответ                 | По каждому утверждению       |
| Эвристические сокращения | Да (опционально)           | Нет                          |
| Вызовы LLM               | 1 (или 0 с эвристиками)    | 2+ (декомпозиция + проверка) |

## Ссылки

- [NVIDIA RAG Evaluation](https://developer.nvidia.com/blog/evaluating-retrieval-augmented-generation-pipelines/)
- [Документация RAGAS](https://docs.ragas.io/)

