# Метрика Semantic Similarity (Семантическое сходство)

## Глоссарий

- **Семантическое сходство** — мера близости двух текстов по смыслу
- **Эмбеддинг** — числовое векторное представление текста
- **Косинусное сходство** — мера близости двух векторов (от -1 до 1, обычно от 0 до 1 для текста)
- **Эталон (Reference)** — ожидаемый правильный ответ

## Описание

Метрика оценивает, насколько семантически похож ответ AI на эталонный ответ. В отличие от метрик, использующих LLM в качестве судьи, эта метрика полагается исключительно на модели эмбеддингов для вычисления векторных представлений обоих текстов и последующего расчёта косинусного сходства между ними.

Это делает метрику:
- **Быстрой** — не требуется инференс LLM, только вычисление эмбеддингов
- **Экономичной** — эмбеддинги обычно дешевле вызовов LLM
- **Детерминированной** — одинаковые тексты всегда дают одинаковый скор (при той же модели эмбеддингов)

## Пример

**Эталон:** «Москва является столицей России.»

**Ответ AI:** «Столица Российской Федерации — город Москва.»

**Скор:** высокое сходство = **0.95 (95%)**

---

**Семантически отличающийся ответ:**

**Ответ AI:** «Россия — самая большая страна в мире по площади.»

**Скор:** среднее сходство = **0.65 (65%)**

---

**Полностью несвязанный ответ:**

**Ответ AI:** «Искусственный интеллект — это область компьютерных наук.»

**Скор:** низкое сходство = **0.25 (25%)**

## Интерпретация скора

|  Скор   |                   Значение                    |
|---------|-----------------------------------------------|
| 90-100% | Почти идентичный смысл                        |
| 70-90%  | Схожий смысл, та же основная информация       |
| 50-70%  | Частично связаны, есть пересечение            |
| 0-50%   | Разный смысл, мало семантического пересечения |

## Важные замечания

- **Противоречия могут иметь высокий скор**: Противоречащие утверждения на одну тему могут иметь высокое семантическое сходство, так как обсуждают одни и те же концепции. «Земля плоская» и «Земля имеет форму шара» получат умеренно высокий скор, потому что оба текста обсуждают форму Земли.
- **Длина имеет значение**: Очень длинные ответы по сравнению с короткими эталонами могут иметь меньшее сходство из-за эффектов усреднения эмбеддингов.
- **Согласованность языка**: Для лучших результатов ответ и эталон должны быть на одном языке.

## Алгоритм

1. **Входные тексты** — получаем ответ и эталонный текст
2. **Вычисление эмбеддингов** — преобразуем оба текста в векторные представления с помощью моделей эмбеддингов
3. **Вычисление косинусного сходства** — рассчитываем косинусное сходство между двумя векторами
4. **Применение порога (опционально)** — если задан порог, преобразуем в бинарный результат: 1.0 (pass) или 0.0 (fail)

## Формула

```
score = cosine_similarity(embed(ответ), embed(эталон))
```

Где:
- `embed(текст)` — векторное представление текста от модели эмбеддингов
- `cosine_similarity(a, b)` — (a · b) / (||a|| × ||b||)

С опциональным порогом:

```
final_score = raw_score >= threshold ? 1.0 : 0.0
```

## Конфигурация

| Параметр  |  Тип   | По умолчанию  |                                         Описание                                         |
|-----------|--------|---------------|------------------------------------------------------------------------------------------|
| threshold | Double | null          | Опциональный порог для бинарного результата. Если null, возвращается сырой скор сходства |
| models    | List   | все доступные | Модели эмбеддингов для мультимодельной оценки                                            |

## Ссылки

- [Статья Sentence Transformers](https://arxiv.org/pdf/2108.06130.pdf)
- [Документация RAGAS](https://github.com/explodinggradients/ragas)

